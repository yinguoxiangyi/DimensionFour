# DimensionFour

## 原代码思路

1. 对每帧进行目标检测--->对所有图片取中位值提取背景图片--->将检测出的目标进行目标跟踪--->将已经编号的目标进行简单筛选--->将筛选后的目标和背景图片进行融合并组装成视频。

2. 实际上等同于 对含有特定目标的帧进行组装 成视频 

## 针对原代码优化的点

1. 去掉了目标跟踪时的跨帧填充

1. 由于原代码中yolov3.h5文件始终无法加载，将原代码中目标识别方法改为了yolov3的darknet版

1. 在最初的目标识别就只识别特定目标，过滤掉了不感兴趣目标

1. 不组装不含相关目标的空帧

1. 去掉了原代码中的多个视频融合的功能，修改为只对单个视频进行摘要

1. 修改 filter_motion_stage.py 28行的 distance 阈值 ， 越小 代表 最终出现在摘要文件中目标数越多

## 计划优化方向

1. 时间轴的压缩，将不同时间段的目标尽量压缩至同一时间段

## 命令
```shell
cd DimensionFour
git branch work
python3 -m dimensionfour.preprocess --input dataset/preferred.mp4 --filter 1 (1代表只识别 人，即只将 人 摘要出来)
python3 -m dimensionfour.assemble --input preferred.mp4.d4artifact.zip --output summary.avi
```


